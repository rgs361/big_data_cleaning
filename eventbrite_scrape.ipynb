{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78107549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed77b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_links(page_number):\n",
    "    \"\"\"\n",
    "    Fetches event links from a specific page number on Eventbrite.\n",
    "    Returns a set of URLs.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.eventbrite.com/d/ny--new-york/all-events/?page={page_number}\"\n",
    "    \n",
    "    # Rotate user agents or use a standard one to look like a browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        \n",
    "        # Check if we've been redirected to page 1 (common behavior when pages run out)\n",
    "        # or if we hit a 404\n",
    "        if response.status_code == 404:\n",
    "            return set()\n",
    "        if response.url != url and \"page=1\" not in response.url and page_number != 1:\n",
    "            print(f\"  [!] Redirected to {response.url} - assuming end of pages.\")\n",
    "            return set()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        event_links = set()\n",
    "\n",
    "        # Method: JSON-LD (Structured Data) extraction\n",
    "        scripts = soup.find_all('script', type='application/ld+json')\n",
    "        \n",
    "        for script in scripts:\n",
    "            try:\n",
    "                data = json.loads(script.string)\n",
    "                # Helper to extract url from a single item dict\n",
    "                def extract_url(item):\n",
    "                    if 'url' in item:\n",
    "                        return item['url']\n",
    "                    elif 'item' in item and 'url' in item['item']: # Nested Schema\n",
    "                        return item['item']['url']\n",
    "                    return None\n",
    "\n",
    "                if isinstance(data, list):\n",
    "                    for item in data:\n",
    "                        url = extract_url(item)\n",
    "                        if url: event_links.add(url)\n",
    "                \n",
    "                elif isinstance(data, dict):\n",
    "                    if 'itemListElement' in data:\n",
    "                        for item in data['itemListElement']:\n",
    "                            url = extract_url(item)\n",
    "                            if url: event_links.add(url)\n",
    "            except (json.JSONDecodeError, TypeError):\n",
    "                continue\n",
    "        \n",
    "        # Fallback: If JSON fails, look for 'a' tags with specific patterns\n",
    "        # Note: Eventbrite changes classes often, so checking href for '/e/' is safer\n",
    "        if not event_links:\n",
    "            links = soup.find_all('a', href=True)\n",
    "            for link in links:\n",
    "                href = link['href']\n",
    "                if '/e/' in href and 'eventbrite.com' in href:\n",
    "                    clean_link = href.split('?')[0] # Remove tracking params\n",
    "                    event_links.add(clean_link)\n",
    "                    \n",
    "        return event_links\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"  [!] Error fetching page {page_number}: {e}\")\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29dc9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_events = set()\n",
    "page = 1\n",
    "max_safety_limit = 500  # Hard stop to prevent infinite loops if logic fails\n",
    "\n",
    "print(\"Starting scraper...\")\n",
    "\n",
    "while page <= max_safety_limit:\n",
    "    print(f\"Scraping Page {page}...\", end=\" \")\n",
    "    \n",
    "    new_links = get_event_links(page)\n",
    "    \n",
    "    # Stop condition: If no links are returned, we have likely reached the end\n",
    "    if not new_links:\n",
    "        print(\"No events found. Reached end of results.\")\n",
    "        break\n",
    "    \n",
    "    # Update master list\n",
    "    initial_count = len(all_events)\n",
    "    all_events.update(new_links)\n",
    "    new_count = len(all_events)\n",
    "    \n",
    "    print(f\"Found {len(new_links)} links. (Total unique: {new_count})\")\n",
    "    \n",
    "    # If we didn't add any new unique links, we might be seeing a 'no results' page \n",
    "    # that still has promoted links we've already seen.\n",
    "    if new_count == initial_count and page > 1:\n",
    "        print(\"  [!] No new unique links found. Stopping to avoid duplicate loops.\")\n",
    "        break\n",
    "\n",
    "    page += 1\n",
    "    \n",
    "    # PAUSE: Random sleep to be polite and avoid IP bans\n",
    "    sleep_time = random.uniform(2, 5) \n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Scraping complete. Found {len(all_events)} unique event links.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64b263df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import concurrent.futures\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eef8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "START_DATE = \"2025-12-12\"  # YYYY-MM-DD\n",
    "DAYS_TO_SCRAPE = 30        # How many days from start date\n",
    "\n",
    "# Concurrency Controls\n",
    "MAX_DAY_WORKERS = 5        # How many days to process at once (Outer Loop)\n",
    "MAX_PAGE_WORKERS = 10       # How many pages to scrape at once per day (Inner Loop)\n",
    "# NOTE: Total concurrent requests = DAY_WORKERS * PAGE_WORKERS (approx 50 here)\n",
    "\n",
    "BASE_URL = \"https://www.eventbrite.com/d/ny--new-york/all-events/\"\n",
    "\n",
    "USER_AGENTS = [\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/101.0.4951.64 Safari/537.36',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "597c89a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(start_date_str, num_days):\n",
    "    \"\"\"Generates a list of date strings (YYYY-MM-DD)\"\"\"\n",
    "    start = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "    return [(start + timedelta(days=i)).strftime(\"%Y-%m-%d\") for i in range(num_days)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25a4855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_single_page(date, page_number):\n",
    "    \"\"\"\n",
    "    Inner Worker: Scrapes a specific page for a specific date.\n",
    "    \"\"\"\n",
    "    # Construct URL with date filters\n",
    "    params = {\n",
    "        'page': page_number,\n",
    "        'start_date': date,\n",
    "        'end_date': date\n",
    "    }\n",
    "    \n",
    "    # Random sleep to prevent \"thundering herd\" on the server\n",
    "    time.sleep(random.uniform(1, 3))\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': random.choice(USER_AGENTS),\n",
    "        'Accept-Language': 'en-US,en;q=0.9',\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(BASE_URL, params=params, headers=headers, timeout=10)\n",
    "        \n",
    "        # 404 or redirect usually means end of results\n",
    "        if response.status_code == 404:\n",
    "            return set()\n",
    "        if \"page=1\" in response.url and page_number > 1:\n",
    "            return set()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        links = set()\n",
    "\n",
    "        # 1. JSON-LD Extraction\n",
    "        scripts = soup.find_all('script', type='application/ld+json')\n",
    "        for script in scripts:\n",
    "            try:\n",
    "                data = json.loads(script.string)\n",
    "                if isinstance(data, list):\n",
    "                    for item in data:\n",
    "                        if 'url' in item: links.add(item['url'])\n",
    "                elif isinstance(data, dict):\n",
    "                    if 'itemListElement' in data:\n",
    "                        for item in data['itemListElement']:\n",
    "                            if 'url' in item: links.add(item['url'])\n",
    "                            elif 'item' in item and 'url' in item['item']:\n",
    "                                links.add(item['item']['url'])\n",
    "            except: continue\n",
    "\n",
    "        # 2. Fallback Extraction\n",
    "        if not links:\n",
    "            for a in soup.find_all('a', href=True):\n",
    "                if '/e/' in a['href'] and 'eventbrite.com' in a['href']:\n",
    "                    links.add(a['href'].split('?')[0])\n",
    "\n",
    "        return links\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"  [!] Error {date} pg {page_number}: {e}\")\n",
    "        return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "feb1b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manage_day_scrape(target_date):\n",
    "    \"\"\"\n",
    "    Outer Worker: Manages the scraping for a single day.\n",
    "    Spawns inner workers to handle pages in batches.\n",
    "    \"\"\"\n",
    "    print(f\"üìÖ Starting Day: {target_date}\")\n",
    "    day_links = set()\n",
    "    current_page = 1\n",
    "    keep_scraping = True\n",
    "    \n",
    "    # We use a ThreadPool for the pages within this day\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_PAGE_WORKERS) as page_executor:\n",
    "        \n",
    "        while keep_scraping:\n",
    "            # Create a batch of pages (e.g., try pages 1, 2, 3 concurrently)\n",
    "            # We batch to avoid queuing 50 pages for a day that has 0 events.\n",
    "            batch_size = MAX_PAGE_WORKERS\n",
    "            futures = {}\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                pg = current_page + i\n",
    "                futures[page_executor.submit(scrape_single_page, target_date, pg)] = pg\n",
    "            \n",
    "            batch_has_results = False\n",
    "            \n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                page_num = futures[future]\n",
    "                try:\n",
    "                    links = future.result()\n",
    "                    if links:\n",
    "                        day_links.update(links)\n",
    "                        batch_has_results = True\n",
    "                        # print(f\"   -> {target_date} Page {page_num}: Found {len(links)} links\")\n",
    "                    else:\n",
    "                        # If a page returns empty, we might have hit the end.\n",
    "                        pass\n",
    "                except Exception:\n",
    "                    continue\n",
    "            \n",
    "            # Decision Logic:\n",
    "            # If the entire batch returned 0 links, we assume the day is done.\n",
    "            # (Or if we reached a safety limit like 50 pages)\n",
    "            if not batch_has_results or current_page > 50:\n",
    "                keep_scraping = False\n",
    "            else:\n",
    "                current_page += batch_size\n",
    "                time.sleep(1) # Breath between batches\n",
    "\n",
    "    print(f\"‚úÖ Finished {target_date}: {len(day_links)} total events.\")\n",
    "    return day_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28555794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Scrape for 30 days...\n",
      "Configuration: 5 Day-Workers x 10 Page-Workers\n",
      "üìÖ Starting Day: 2025-12-12\n",
      "üìÖ Starting Day: 2025-12-13\n",
      "üìÖ Starting Day: 2025-12-14\n",
      "üìÖ Starting Day: 2025-12-15\n",
      "üìÖ Starting Day: 2025-12-16\n",
      "‚úÖ Finished 2025-12-15: 304 total events.\n",
      "üìÖ Starting Day: 2025-12-17\n",
      "‚úÖ Finished 2025-12-16: 455 total events.\n",
      "üìÖ Starting Day: 2025-12-18\n",
      "‚úÖ Finished 2025-12-13: 700 total events.\n",
      "üìÖ Starting Day: 2025-12-19\n",
      "‚úÖ Finished 2025-12-14: 708 total events.\n",
      "üìÖ Starting Day: 2025-12-20\n",
      "‚úÖ Finished 2025-12-12: 700 total events.\n",
      "üìÖ Starting Day: 2025-12-21\n",
      "‚úÖ Finished 2025-12-17: 525 total events.\n",
      "üìÖ Starting Day: 2025-12-22\n",
      "‚úÖ Finished 2025-12-18: 570 total events.\n",
      "üìÖ Starting Day: 2025-12-23\n",
      "‚úÖ Finished 2025-12-21: 693 total events.\n",
      "üìÖ Starting Day: 2025-12-24\n",
      "‚úÖ Finished 2025-12-19: 705 total events.\n",
      "üìÖ Starting Day: 2025-12-25\n",
      "‚úÖ Finished 2025-12-20: 706 total events.\n",
      "üìÖ Starting Day: 2025-12-26\n",
      "‚úÖ Finished 2025-12-22: 188 total events.\n",
      "üìÖ Starting Day: 2025-12-27\n",
      "‚úÖ Finished 2025-12-23: 305 total events.\n",
      "üìÖ Starting Day: 2025-12-28\n",
      "‚úÖ Finished 2025-12-24: 174 total events.\n",
      "üìÖ Starting Day: 2025-12-29\n",
      "‚úÖ Finished 2025-12-25: 194 total events.\n",
      "üìÖ Starting Day: 2025-12-30\n",
      "‚úÖ Finished 2025-12-26: 456 total events.\n",
      "üìÖ Starting Day: 2025-12-31\n",
      "‚úÖ Finished 2025-12-29: 159 total events.\n",
      "üìÖ Starting Day: 2026-01-01\n",
      "‚úÖ Finished 2025-12-27: 709 total events.\n",
      "üìÖ Starting Day: 2026-01-02\n",
      "‚úÖ Finished 2025-12-30: 200 total events.\n",
      "üìÖ Starting Day: 2026-01-03\n",
      "‚úÖ Finished 2026-01-02: 172 total events.\n",
      "üìÖ Starting Day: 2026-01-04\n",
      "‚úÖ Finished 2025-12-28: 568 total events.\n",
      "üìÖ Starting Day: 2026-01-05\n",
      "‚úÖ Finished 2026-01-03: 0 total events.\n",
      "üìÖ Starting Day: 2026-01-06\n",
      "‚úÖ Finished 2025-12-31: 399 total events.\n",
      "üìÖ Starting Day: 2026-01-07\n",
      "‚úÖ Finished 2026-01-04: 0 total events.\n",
      "üìÖ Starting Day: 2026-01-08\n",
      "‚úÖ Finished 2026-01-01: 258 total events.\n",
      "üìÖ Starting Day: 2026-01-09\n",
      "‚úÖ Finished 2026-01-06: 0 total events.\n",
      "üìÖ Starting Day: 2026-01-10\n",
      "‚úÖ Finished 2026-01-05: 0 total events.\n",
      "‚úÖ Finished 2026-01-07: 0 total events.\n",
      "‚úÖ Finished 2026-01-08: 0 total events.\n",
      "‚úÖ Finished 2026-01-09: 0 total events.\n",
      "‚úÖ Finished 2026-01-10: 0 total events.\n",
      "------------------------------\n",
      "SCRAPE COMPLETE.\n",
      "Total Unique Event Links: 9250\n"
     ]
    }
   ],
   "source": [
    "all_unique_links = set()\n",
    "dates_to_scrape = get_dates(START_DATE, DAYS_TO_SCRAPE)\n",
    "\n",
    "print(f\"Starting Scrape for {len(dates_to_scrape)} days...\")\n",
    "print(f\"Configuration: {MAX_DAY_WORKERS} Day-Workers x {MAX_PAGE_WORKERS} Page-Workers\")\n",
    "\n",
    "# Outer Pool: Manages different days\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_DAY_WORKERS) as day_executor:\n",
    "    \n",
    "    # Submit all date tasks\n",
    "    future_to_date = {day_executor.submit(manage_day_scrape, date): date for date in dates_to_scrape}\n",
    "    \n",
    "    for future in concurrent.futures.as_completed(future_to_date):\n",
    "        date = future_to_date[future]\n",
    "        try:\n",
    "            links = future.result()\n",
    "            all_unique_links.update(links)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Critical failure on {date}: {e}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"SCRAPE COMPLETE.\")\n",
    "print(f\"Total Unique Event Links: {len(all_unique_links)}\")\n",
    "\n",
    "# Save to file\n",
    "with open('nyc_events_dated.txt', 'w') as f:\n",
    "    for link in all_unique_links:\n",
    "        f.write(f\"{link}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682a39a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Reading links from nyc_events_dated.txt...\n",
      "üìã Processing 20 events with 5 concurrent workers...\n",
      "\n",
      "‚úÖ Finished: SUNDAY RESET BREATH WORK SERIES  ‚ú¶Ô∏é Soma...\n",
      "‚úÖ Finished: Cold Beer & A Good Laugh at The Grisly P...\n",
      "‚úÖ Finished: Tech and Business Networking | Elevating...\n",
      "‚úÖ Finished: Earth & Art: Hand-Built Pottery with Jun...\n",
      "‚úÖ Finished: HIGHLIFE SATURDAYS ROOFTOP PARTY - NYC 3...\n",
      "‚úÖ Finished: The Everri Holiday Sample Sale ‚Äî Jewelry...\n",
      "‚úÖ Finished: New Year Eve Hottest Bollywood  Desi Par...\n",
      "‚úÖ Finished: Long Pose Figure Drawing & Painting Work...\n",
      "‚úÖ Finished: New Year's Eve at Bar Sprezzatura...\n",
      "‚úÖ Finished: Jersey City Conspiracy Game: The Outdoor...\n",
      "‚úÖ Finished: Trauma-Informed Vinyasa Yoga...\n",
      "‚úÖ Finished: Christians Over Coffee: Manhattan Meetup...\n",
      "‚úÖ Finished: LIVE Music EVERY Monday Night at the Bro...\n",
      "‚úÖ Finished: Boozy Sundae Decorating Class...\n",
      "‚úÖ Finished: Traditional Turkish Mosaic Lamp Workshop...\n",
      "‚úÖ Finished: Community Heart Space and Breathwork - N...\n",
      "‚úÖ Finished: Presepio: The Italian Nativity Scene...\n",
      "‚úÖ Finished: Donate a Toy and get a Free Drink!...\n",
      "‚úÖ Finished: NYC BOAT PARTY  CRUISE |  SKYLINE VIEWS...\n",
      "‚úÖ Finished: Lulla's Winter Study at Motto Chelsea...\n",
      "\n",
      "--- JSON OUTPUT ---\n",
      "[\n",
      "    {\n",
      "        \"Title\": \"SUNDAY RESET BREATH WORK SERIES  \\u2726\\ufe0e Somatic Soul Breath\",\n",
      "        \"DateTime\": null,\n",
      "        \"DateTimeStr\": \"TBD\",\n",
      "        \"Location\": \"449 Nostrand Avenue #2nd flr, Brooklyn, NY 11216\",\n",
      "        \"Categories\": [\n",
      "            \"Class, Training, or Workshop\",\n",
      "            \"Health & Wellness\",\n",
      "            \"Yoga\"\n",
      "        ],\n",
      "        \"EventID\": \"1975603814190\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/sunday-reset-breath-work-series-somatic-soul-breath-tickets-1975603814190\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Cold Beer & A Good Laugh at The Grisly Pear Midtown\",\n",
      "        \"DateTime\": 1766966400000,\n",
      "        \"DateTimeStr\": \"2025-12-29 00:00:00 UTC\",\n",
      "        \"Location\": \"243 West 54th Street, New York, NY 10019\",\n",
      "        \"Categories\": [\n",
      "            \"Comedy\",\n",
      "            \"Concert or Performance\",\n",
      "            \"Performing & Visual Arts\"\n",
      "        ],\n",
      "        \"EventID\": \"1470711340209\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/cold-beer-a-good-laugh-at-the-grisly-pear-midtown-tickets-1470711340209\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Tech and Business Networking | Elevating Your Potential - Hoboken\",\n",
      "        \"DateTime\": 1766012400000,\n",
      "        \"DateTimeStr\": \"2025-12-17 23:00:00 UTC\",\n",
      "        \"Location\": \"1313 Willow Avenue, Hoboken, NJ 07030\",\n",
      "        \"Categories\": [\n",
      "            \"Business & Professional\",\n",
      "            \"Meeting or Networking Event\",\n",
      "            \"Startups & Small Business\"\n",
      "        ],\n",
      "        \"EventID\": \"1640869628229\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/tech-and-business-networking-elevating-your-potential-hoboken-tickets-1640869628229\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Earth & Art: Hand-Built Pottery with Juniper Foster\",\n",
      "        \"DateTime\": null,\n",
      "        \"DateTimeStr\": \"TBD\",\n",
      "        \"Location\": \"34-14 Broadway, astoria, NY 11106\",\n",
      "        \"Categories\": [\n",
      "            \"Class, Training, or Workshop\",\n",
      "            \"Craft\",\n",
      "            \"Performing & Visual Arts\"\n",
      "        ],\n",
      "        \"EventID\": \"1975189408692\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/earth-art-hand-built-pottery-with-juniper-foster-tickets-1975189408692\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"HIGHLIFE SATURDAYS ROOFTOP PARTY - NYC 360 views @ Highbar\",\n",
      "        \"DateTime\": 1765677600000,\n",
      "        \"DateTimeStr\": \"2025-12-14 02:00:00 UTC\",\n",
      "        \"Location\": \"346 West 40th Street, New York, NY 10018\",\n",
      "        \"Categories\": [\n",
      "            \"Latin\",\n",
      "            \"Music\",\n",
      "            \"Party or Social Gathering\"\n",
      "        ],\n",
      "        \"EventID\": \"1732691730609\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/highlife-saturdays-rooftop-party-nyc-360-views-highbar-tickets-1732691730609\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"The Everri Holiday Sample Sale \\u2014 Jewelry from $5 and up at our NYC Studio.\",\n",
      "        \"DateTime\": null,\n",
      "        \"DateTimeStr\": \"TBD\",\n",
      "        \"Location\": \"150 West 25th Street #8th floor, New York, NY 10001\",\n",
      "        \"Categories\": [\n",
      "            \"Fashion\",\n",
      "            \"Fashion & Beauty\",\n",
      "            \"Festival or Fair\"\n",
      "        ],\n",
      "        \"EventID\": \"1968183311266\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/the-everri-holiday-sample-sale-jewelry-from-5-and-up-at-our-nyc-studio-tickets-1968183311266\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"New Year Eve Hottest Bollywood  Desi Party   @RACKET NYC\",\n",
      "        \"DateTime\": 1767232800000,\n",
      "        \"DateTimeStr\": \"2026-01-01 02:00:00 UTC\",\n",
      "        \"Location\": \"431 West 16th Street, New York, NY 10011\",\n",
      "        \"Categories\": [\n",
      "            \"Cultural\",\n",
      "            \"Music\",\n",
      "            \"Party or Social Gathering\"\n",
      "        ],\n",
      "        \"EventID\": \"1977187088807\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/new-year-eve-hottest-bollywood-desi-party-racket-nyc-tickets-1977187088807\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Long Pose Figure Drawing & Painting Workshop by Lucas Bononi\",\n",
      "        \"DateTime\": null,\n",
      "        \"DateTimeStr\": \"TBD\",\n",
      "        \"Location\": \"101 73rd Street Unit 54, North Bergen, NJ 07047\",\n",
      "        \"Categories\": [\n",
      "            \"Class, Training, or Workshop\",\n",
      "            \"Painting\",\n",
      "            \"Performing & Visual Arts\"\n",
      "        ],\n",
      "        \"EventID\": \"810734126597\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/long-pose-figure-drawing-painting-workshop-by-lucas-bononi-tickets-810734126597\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"New Year's Eve at Bar Sprezzatura\",\n",
      "        \"DateTime\": 1767232800000,\n",
      "        \"DateTimeStr\": \"2026-01-01 02:00:00 UTC\",\n",
      "        \"Location\": \"251 West 48th Street, New York, NY 10036\",\n",
      "        \"Categories\": [\n",
      "            \"New Years Eve\",\n",
      "            \"Party or Social Gathering\",\n",
      "            \"Seasonal & Holiday\"\n",
      "        ],\n",
      "        \"EventID\": \"1975838804051\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/new-years-eve-at-bar-sprezzatura-tickets-1975838804051\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Jersey City Conspiracy Game: The Outdoor Escape\",\n",
      "        \"DateTime\": 1767283200000,\n",
      "        \"DateTimeStr\": \"2026-01-01 16:00:00 UTC\",\n",
      "        \"Location\": \"277 County Road 618, Jersey City, NJ 07302\",\n",
      "        \"Categories\": [\n",
      "            \"Game or Competition\",\n",
      "            \"Hobbies & Special Interest\",\n",
      "            \"Other\"\n",
      "        ],\n",
      "        \"EventID\": \"1976083875065\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/jersey-city-conspiracy-game-the-outdoor-escape-tickets-1976083875065\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Trauma-Informed Vinyasa Yoga\",\n",
      "        \"DateTime\": null,\n",
      "        \"DateTimeStr\": \"TBD\",\n",
      "        \"Location\": \"53 West 39th Street #floor 2, New York, NY 10018\",\n",
      "        \"Categories\": [\n",
      "            \"Class, Training, or Workshop\",\n",
      "            \"Health & Wellness\",\n",
      "            \"Yoga\"\n",
      "        ],\n",
      "        \"EventID\": \"1977306130865\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/trauma-informed-vinyasa-yoga-tickets-1977306130865\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Christians Over Coffee: Manhattan Meetup\",\n",
      "        \"DateTime\": 1766854800000,\n",
      "        \"DateTimeStr\": \"2025-12-27 17:00:00 UTC\",\n",
      "        \"Location\": \"Manhattan, New York, NY 10019\",\n",
      "        \"Categories\": [\n",
      "            \"Christianity\",\n",
      "            \"Meeting or Networking Event\",\n",
      "            \"Religion & Spirituality\"\n",
      "        ],\n",
      "        \"EventID\": \"1770799060659\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/christians-over-coffee-manhattan-meetup-tickets-1770799060659\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"LIVE Music EVERY Monday Night at the Brooklyn Music Kitchen\",\n",
      "        \"DateTime\": 1766448000000,\n",
      "        \"DateTimeStr\": \"2025-12-23 00:00:00 UTC\",\n",
      "        \"Location\": \"177 Vanderbilt Avenue, Brooklyn, NY 11205\",\n",
      "        \"Categories\": [\n",
      "            \"Concert or Performance\",\n",
      "            \"Music\",\n",
      "            \"Other\"\n",
      "        ],\n",
      "        \"EventID\": \"1370636864759\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/live-music-every-monday-night-at-the-brooklyn-music-kitchen-tickets-1370636864759\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Boozy Sundae Decorating Class\",\n",
      "        \"DateTime\": null,\n",
      "        \"DateTimeStr\": \"TBD\",\n",
      "        \"Location\": \"38-15 23rd Avenue, Queens, NY 11105\",\n",
      "        \"Categories\": [\n",
      "            \"Class, Training, or Workshop\",\n",
      "            \"Food & Drink\",\n",
      "            \"Spirits\"\n",
      "        ],\n",
      "        \"EventID\": \"1548505394319\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/boozy-sundae-decorating-class-tickets-1548505394319\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Traditional Turkish Mosaic Lamp Workshop in NYC\",\n",
      "        \"DateTime\": null,\n",
      "        \"DateTimeStr\": \"TBD\",\n",
      "        \"Location\": \"325 West 38th Street #suite 1405, New York, NY 10018\",\n",
      "        \"Categories\": [\n",
      "            \"Class, Training, or Workshop\"\n",
      "        ],\n",
      "        \"EventID\": \"1704341193389\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/traditional-turkish-mosaic-lamp-workshop-in-nyc-tickets-1704341193389\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Community Heart Space and Breathwork - NYC\",\n",
      "        \"DateTime\": null,\n",
      "        \"DateTimeStr\": \"TBD\",\n",
      "        \"Location\": \"online via zoom, New York, NY 10002\",\n",
      "        \"Categories\": [\n",
      "            \"Class, Training, or Workshop\",\n",
      "            \"Health & Wellness\",\n",
      "            \"Personal health\"\n",
      "        ],\n",
      "        \"EventID\": \"1964730471730\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/community-heart-space-and-breathwork-nyc-tickets-1964730471730\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Presepio: The Italian Nativity Scene\",\n",
      "        \"DateTime\": null,\n",
      "        \"DateTimeStr\": \"TBD\",\n",
      "        \"Location\": \"151 Mulberry Street, New York, NY 10013\",\n",
      "        \"Categories\": [\n",
      "            \"Christmas\",\n",
      "            \"Seasonal & Holiday\",\n",
      "            \"Seminar or Talk\"\n",
      "        ],\n",
      "        \"EventID\": \"1976414383625\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/presepio-the-italian-nativity-scene-tickets-1976414383625\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Donate a Toy and get a Free Drink!\",\n",
      "        \"DateTime\": 1765989000000,\n",
      "        \"DateTimeStr\": \"2025-12-17 16:30:00 UTC\",\n",
      "        \"Location\": \"339 9th Street, Brooklyn, NY 11215\",\n",
      "        \"Categories\": [\n",
      "            \"Charity & Causes\",\n",
      "            \"Party or Social Gathering\",\n",
      "            \"Poverty\"\n",
      "        ],\n",
      "        \"EventID\": \"1977226963072\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/donate-a-toy-and-get-a-free-drink-tickets-1977226963072\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"NYC BOAT PARTY  CRUISE |  SKYLINE VIEWS\",\n",
      "        \"DateTime\": 1765681200000,\n",
      "        \"DateTimeStr\": \"2025-12-14 03:00:00 UTC\",\n",
      "        \"Location\": \"299 South Street, New York, NY 10002\",\n",
      "        \"Categories\": [\n",
      "            \"Music\",\n",
      "            \"Party or Social Gathering\",\n",
      "            \"Top 40\"\n",
      "        ],\n",
      "        \"EventID\": \"1096555169029\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/nyc-boat-party-cruise-skyline-views-tickets-1096555169029\"\n",
      "    },\n",
      "    {\n",
      "        \"Title\": \"Lulla's Winter Study at Motto Chelsea\",\n",
      "        \"DateTime\": 1766156400000,\n",
      "        \"DateTimeStr\": \"2025-12-19 15:00:00 UTC\",\n",
      "        \"Location\": \"113 West 24th Street, New York, NY 10001\",\n",
      "        \"Categories\": [\n",
      "            \"Other\",\n",
      "            \"Party or Social Gathering\",\n",
      "            \"Seasonal & Holiday\"\n",
      "        ],\n",
      "        \"EventID\": \"1977416163977\",\n",
      "        \"Link\": \"https://www.eventbrite.com/e/lullas-winter-study-at-motto-chelsea-tickets-1977416163977\"\n",
      "    }\n",
      "]\n",
      "\n",
      "‚úÖ Done! Saved 20 events to eventbrite_events_corrected.json\n"
     ]
    }
   ],
   "source": [
    "from curl_cffi import requests as crequests \n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# --- Configuration ---\n",
    "API_ENDPOINT = \"https://www.eventbrite.com/api/v3/destination/events/?event_ids={}&expand=event_sales_status,image,primary_venue,ticket_availability,taxonomy,tags,upcoming_occurrences\"\n",
    "# Recommended: Keep this low (3-5) to avoid IP bans.\n",
    "MAX_WORKERS = 5\n",
    "\n",
    "def get_fallback_data_from_html(url):\n",
    "    \"\"\"\n",
    "    Fallback: Scrapes the schema.org JSON-LD from the HTML page \n",
    "    to find Date AND Location if the API fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = crequests.get(url, impersonate=\"chrome110\", timeout=15)\n",
    "        if response.status_code != 200: return None, None, None\n",
    "\n",
    "        matches = re.findall(r'<script type=\"application/ld\\+json\">(.*?)</script>', response.text, re.DOTALL)\n",
    "        \n",
    "        found_date = None\n",
    "        found_date_str = None\n",
    "        found_location = None\n",
    "\n",
    "        for match in matches:\n",
    "            try:\n",
    "                data = json.loads(match)\n",
    "                if isinstance(data, list): data = data[0]\n",
    "                \n",
    "                if data.get('@type') in ['Event', 'SocialEvent', 'MusicEvent']:\n",
    "                    # 1. Fallback Date\n",
    "                    start_str = data.get('startDate')\n",
    "                    if start_str:\n",
    "                        dt = datetime.fromisoformat(start_str)\n",
    "                        if dt.tzinfo is None: dt = dt.replace(tzinfo=timezone.utc)\n",
    "                        found_date = int(dt.timestamp() * 1000)\n",
    "                        found_date_str = dt.astimezone(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')\n",
    "\n",
    "                    # 2. Fallback Location\n",
    "                    loc_data = data.get('location')\n",
    "                    if isinstance(loc_data, dict):\n",
    "                        venue_name = loc_data.get('name', '')\n",
    "                        address = loc_data.get('address', {})\n",
    "                        parts = [venue_name]\n",
    "                        if isinstance(address, dict):\n",
    "                            parts.extend([\n",
    "                                address.get('streetAddress'),\n",
    "                                address.get('addressLocality'),\n",
    "                                address.get('addressRegion'),\n",
    "                                address.get('postalCode')\n",
    "                            ])\n",
    "                        elif isinstance(address, str):\n",
    "                            parts.append(address)\n",
    "                        found_location = \", \".join([p for p in parts if p])\n",
    "            except:\n",
    "                continue\n",
    "        return found_date, found_date_str, found_location\n",
    "    except Exception:\n",
    "        return None, None, None\n",
    "\n",
    "def get_event_data_via_api(url):\n",
    "    # 1. Extract Event ID\n",
    "    event_id_match = re.search(r'(\\d{10,})', url)\n",
    "    if not event_id_match:\n",
    "        return None\n",
    "    \n",
    "    event_id = event_id_match.group(1)\n",
    "    api_url = API_ENDPOINT.format(event_id)\n",
    "\n",
    "    # 2. Call API\n",
    "    try:\n",
    "        response = crequests.get(\n",
    "            api_url,\n",
    "            impersonate=\"chrome110\",\n",
    "            headers={\"Accept\": \"application/json\"},\n",
    "            timeout=15\n",
    "        )\n",
    "        if response.status_code != 200: return None\n",
    "\n",
    "        data = response.json()\n",
    "        if 'events' not in data or not data['events']: return None\n",
    "        event = data['events'][0]\n",
    "        \n",
    "        # --- EXTRACTION ---\n",
    "        \n",
    "        # Title\n",
    "        title = \"No Title\"\n",
    "        name_obj = event.get('name')\n",
    "        if isinstance(name_obj, dict): title = name_obj.get('text', \"No Title\")\n",
    "        elif isinstance(name_obj, str): title = name_obj\n",
    "\n",
    "        # Date Helper\n",
    "        def parse_start_obj(s_obj):\n",
    "            if not isinstance(s_obj, dict): return None, None\n",
    "            d_str = s_obj.get('utc') or s_obj.get('local')\n",
    "            if not d_str: return None, None\n",
    "            try:\n",
    "                if d_str.endswith('Z'): d_str = d_str.replace('Z', '+00:00')\n",
    "                dt = datetime.fromisoformat(d_str)\n",
    "                if dt.tzinfo is None: dt = dt.replace(tzinfo=timezone.utc)\n",
    "                return int(dt.timestamp() * 1000), dt.astimezone(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')\n",
    "            except: return None, None\n",
    "\n",
    "        # Date Attempt\n",
    "        timestamp, datetime_str = parse_start_obj(event.get('start'))\n",
    "        if not timestamp:\n",
    "            occurrences = event.get('upcoming_occurrences')\n",
    "            if occurrences and isinstance(occurrences, list):\n",
    "                timestamp, datetime_str = parse_start_obj(occurrences[0].get('start'))\n",
    "        \n",
    "        # Location Attempt\n",
    "        location = None\n",
    "        venue = event.get('primary_venue')\n",
    "        if isinstance(venue, dict):\n",
    "            address_obj = venue.get('address')\n",
    "            if isinstance(address_obj, dict):\n",
    "                location = address_obj.get('localized_address_display')\n",
    "            \n",
    "            if not location:\n",
    "                venue_name = venue.get('name', '')\n",
    "                parts = [venue_name]\n",
    "                if isinstance(address_obj, dict):\n",
    "                    parts.extend([\n",
    "                        address_obj.get('address_1'),\n",
    "                        address_obj.get('city'),\n",
    "                        address_obj.get('region'),\n",
    "                        address_obj.get('postal_code')\n",
    "                    ])\n",
    "                clean_parts = [p for p in parts if p and p.strip()]\n",
    "                if clean_parts: location = \", \".join(clean_parts)\n",
    "\n",
    "        if not location and event.get('online_event'): location = \"Online\"\n",
    "\n",
    "        # Trigger Fallback if needed\n",
    "        if not timestamp or not location:\n",
    "            fb_ts, fb_str, fb_loc = get_fallback_data_from_html(url)\n",
    "            if not timestamp: timestamp, datetime_str = fb_ts, fb_str\n",
    "            if not location: location = fb_loc\n",
    "\n",
    "        # Categories\n",
    "        raw_categories = set()\n",
    "        tax = event.get('taxonomy')\n",
    "        if isinstance(tax, dict):\n",
    "            cat = tax.get('category')\n",
    "            if isinstance(cat, dict): raw_categories.add(cat.get('name', ''))\n",
    "            sub = tax.get('sub_category')\n",
    "            if isinstance(sub, dict): raw_categories.add(sub.get('name', ''))\n",
    "        tags = event.get('tags')\n",
    "        if isinstance(tags, list):\n",
    "            for tag in tags:\n",
    "                if isinstance(tag, dict): raw_categories.add(tag.get('display_name', ''))\n",
    "                elif isinstance(tag, str): raw_categories.add(tag)\n",
    "        cleaned_categories = [c for c in raw_categories if c and c[0].isupper()]\n",
    "\n",
    "        return {\n",
    "            \"Title\": title,\n",
    "            \"DateTime\": timestamp,\n",
    "            \"DateTimeStr\": datetime_str or \"TBD\",\n",
    "            \"Location\": location or \"Location TBD\",\n",
    "            \"Categories\": sorted(cleaned_categories),\n",
    "            \"EventID\": event_id,\n",
    "            \"Link\": url\n",
    "        }\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# --- Main Execution (Parallelized) ---\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"nyc_events_dated.txt\"\n",
    "    output_file = \"eventbrite_events_corrected.json\"\n",
    "    limit = 20  # How many to process\n",
    "\n",
    "    print(f\"üöÄ Reading links from {input_file}...\")\n",
    "    \n",
    "    links = []\n",
    "    try:\n",
    "        with open(input_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                clean_line = line.strip()\n",
    "                if clean_line and clean_line.startswith(\"http\"):\n",
    "                    links.append(clean_line)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Error: File '{input_file}' not found.\")\n",
    "        exit()\n",
    "\n",
    "    # target_links = links[:limit]\n",
    "    target_links = links\n",
    "    print(f\"üìã Processing {len(target_links)} events with {MAX_WORKERS} concurrent workers...\\n\")\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    # --- PARALLEL EXECUTION START ---\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        # Submit all tasks to the pool\n",
    "        # This creates a dictionary: {Future Object: URL}\n",
    "        future_to_url = {executor.submit(get_event_data_via_api, url): url for url in target_links}\n",
    "        \n",
    "        # as_completed yields futures as they finish (not necessarily in order of submission)\n",
    "        for future in as_completed(future_to_url):\n",
    "            url = future_to_url[future]\n",
    "            try:\n",
    "                data = future.result()\n",
    "                if data:\n",
    "                    results.append(data)\n",
    "                    print(f\"‚úÖ Finished: {data['Title'][:40]}...\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Failed: {url}\")\n",
    "            except Exception as exc:\n",
    "                print(f\"‚ùå Exception for {url}: {exc}\")\n",
    "    # --- PARALLEL EXECUTION END ---\n",
    "\n",
    "    print(\"\\n--- JSON OUTPUT ---\")\n",
    "    print(json.dumps(results, indent=4))\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Done! Saved {len(results)} events to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca43eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data_cleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
